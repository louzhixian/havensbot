# Voice-to-Text Feature Design

## Overview

Add voice message transcription and text polishing to the Editorial Channel. When users send voice messages, the bot automatically transcribes them using Whisper, polishes the text with LLM, and posts a clean draft in a thread.

## Requirements

- **Trigger**: Voice messages in `EDITORIAL_CHANNEL_ID` only
- **Transcription**: Whisper service running on Mac, accessible via Tailscale
- **Text Polishing**: Use existing LLM to remove filler words, repetition, and verbal tics while preserving personal tone
- **Output**: Create thread with polished draft only (hide raw transcript)
- **Status Feedback**: Add â³ reaction during processing, update to âœ… on success or âŒ on failure
- **Retry**: Auto-retry on Whisper failures, plus manual retry via ğŸ”„ reaction

## Architecture

### Components

**1. Mac Whisper Service:**
- Docker container: `onerahmet/openai-whisper-asr-webservice`
- Listen on port 9000
- Accessible from VPS via Tailscale MagicDNS: `http://mac-hostname:9000`
- Model: `medium` (recommended for quality/speed balance)

**2. ArkCore Modules:**
```
src/voice/
  types.ts              // Type definitions
  whisperClient.ts      // Whisper API client
  textPolisher.ts       // LLM text polishing logic
  voiceHandler.ts       // Main processing flow
  retryCache.ts         // Retry record cache
```

**3. Configuration (.env):**
```bash
VOICE_TO_TEXT_ENABLED=true
WHISPER_API_URL=http://mac-hostname.tail-scale.ts.net:9000
WHISPER_TIMEOUT_MS=60000
WHISPER_MAX_RETRIES=2
```

## Data Flow

### Normal Flow
1. User sends voice message in Editorial Channel
2. Bot detects audio attachment
3. Add â³ reaction immediately
4. Download audio file to temp directory
5. Call Whisper API to transcribe (with auto-retry)
6. Call LLM to polish transcript
7. Create thread with polished draft
8. Update reaction to âœ…
9. Clean up temp file

### Whisper API Call
```
POST /asr?encode=true&task=transcribe&language=zh&word_timestamps=false
Content-Type: multipart/form-data
Body: audio_file

Response: { "text": "è½¬å½•ç»“æœ..." }
```

### LLM Polishing Prompt
```
ä½ æ˜¯ä¸€ä¸ªæ–‡æœ¬æ•´ç†åŠ©æ‰‹ã€‚è¯·å°†ä»¥ä¸‹è¯­éŸ³è½¬å½•æ–‡æœ¬æ•´ç†æˆæ¸…æ™°çš„ä¹¦é¢æ–‡å­—ï¼š
- å»æ‰å£è¯­åŒ–è¡¨è¾¾ã€è¯­æ°”è¯ã€é‡å¤å†…å®¹
- ä¿æŒè¯´è¯è€…çš„ä¸ªäººè¯­æ°”å’Œè¡¨è¾¾ä¹ æƒ¯
- ä¸è¦æ·»åŠ åŸæ–‡æ²¡æœ‰çš„å†…å®¹
- è¾“å‡ºæ•´ç†åçš„è‰ç¨¿å³å¯ï¼Œæ— éœ€å…¶ä»–è¯´æ˜

è½¬å½•åŸæ–‡ï¼š
{transcribed_text}
```

## Error Handling

### Whisper API Failures
- **Auto-retry**: 2 retries with exponential backoff (3s, 6s)
- **Final failure**: Update reaction to âŒ, create thread with error message
- **Manual retry**: Add ğŸ”„ reaction in error thread, listen for user click

### LLM Failures
- **Graceful degradation**: Post raw transcript with note "æ•´ç†å¤±è´¥ï¼Œä»¥ä¸‹æ˜¯è½¬å½•åŸæ–‡"
- Use existing `callWithFallback` retry mechanism

### Discord API Failures
- Use existing retry logic (`callWithFallback`) for thread creation and reactions

### File Download Failures
- Timeout: 10 seconds
- Failure: âŒ reaction + error message

### Timeout Settings
- Whisper API: 60s
- LLM polishing: 30s
- File download: 10s

## Retry Mechanism

### Auto-Retry
```typescript
async function transcribeWithRetry(audioFile: Buffer): Promise<string> {
  const maxRetries = 2;
  for (let i = 0; i <= maxRetries; i++) {
    try {
      return await callWhisperAPI(audioFile);
    } catch (error) {
      if (i === maxRetries) throw error;
      await sleep(3000 * (i + 1)); // 3s, 6s
    }
  }
}
```

### Manual Retry
- **Trigger**: User clicks ğŸ”„ on error message posted by bot
- **Cache**: Store failed message metadata in memory (1 hour TTL)
- **Limit**: Max 3 manual retries per voice message
- **Implementation**:
  - Monitor `messageReactionAdd` event
  - Verify: reaction is ğŸ”„, message author is bot, user is original sender
  - Retrieve audio URL from cache, reprocess

### Retry Cache
```typescript
interface RetryRecord {
  messageId: string;
  audioUrl: string;
  attempts: number;
  timestamp: number;
}

class RetryCache {
  private cache = new Map<string, RetryRecord>();

  set(messageId: string, record: RetryRecord): void;
  get(messageId: string): RetryRecord | undefined;
  canRetry(messageId: string): boolean; // Check < 3 attempts
  cleanup(): void; // Remove records older than 1 hour
}
```

## Resource Management

### Temporary Files
- **Storage**: `/tmp/arkcore-voice/` or `os.tmpdir()`
- **Naming**: `${messageId}-${timestamp}.${ext}`
- **Cleanup**: Delete in `finally` block, ensure cleanup on all paths

### Concurrency
- No explicit limits on ArkCore side
- Whisper container handles its own concurrency
- Can add queue/semaphore later if needed

### Security
- **Whisper API**: Only accessible via Tailscale, no public exposure
- **File size**: Check `attachment.size` before download (optional 50MB threshold)
- **LLM prompt injection**: System/user role separation, safe for text polishing task

### Logging
- Log each processing step: download, transcribe, polish, publish
- Log Whisper API response time
- Use existing Winston logger

## Deployment

### Mac Setup
```bash
docker run -d \
  --name whisper-service \
  -p 9000:9000 \
  -e ASR_MODEL=medium \
  -e ASR_ENGINE=openai_whisper \
  onerahmet/openai-whisper-asr-webservice:latest

# Health check
curl http://localhost:9000/health
```

### VPS Setup
1. Verify Tailscale connectivity: `curl http://mac-hostname:9000/health`
2. Update `.env` with `WHISPER_API_URL`
3. Rebuild and restart: `docker compose up -d --build`
4. Test in Editorial Channel

### Dependencies
- `form-data` (or use existing HTTP client for multipart uploads)
- Existing: `axios` or similar HTTP client

## Code Structure

### Core Interfaces
```typescript
// types.ts
interface VoiceProcessingResult {
  success: boolean;
  polishedText?: string;
  error?: string;
}

interface RetryRecord {
  messageId: string;
  audioUrl: string;
  attempts: number;
  timestamp: number;
}
```

### Main Functions
```typescript
// voiceHandler.ts
async function handleVoiceMessage(
  message: Message,
  attachment: Attachment
): Promise<void>

// whisperClient.ts
async function transcribe(audioBuffer: Buffer): Promise<string>

// textPolisher.ts
async function polishTranscript(text: string): Promise<string>

// retryCache.ts
class RetryCache {
  set(messageId: string, record: RetryRecord): void
  get(messageId: string): RetryRecord | undefined
  canRetry(messageId: string): boolean
}
```

### Integration Point
```typescript
// src/handlers/messageHandler.ts
if (message.channelId === EDITORIAL_CHANNEL_ID) {
  const voiceAttachment = message.attachments.find(
    att => att.contentType?.startsWith('audio/')
  );
  if (voiceAttachment) {
    await handleVoiceMessage(message, voiceAttachment);
    return; // Don't process further
  }
}
```

## Testing

### Unit Tests
- `whisperClient.ts` - mock API responses (success, failure, timeout)
- `textPolisher.ts` - mock LLM calls
- `retryCache.ts` - cache operations, TTL expiration

### Integration Tests
- End-to-end: send test audio â†’ verify thread creation and content
- Use 5-second test audio sample
- Mock Discord API responses

### Manual Testing Checklist
- [ ] Normal flow: voice â†’ â³ â†’ thread â†’ âœ…
- [ ] Auto-retry: simulate Whisper unavailable â†’ retries â†’ âŒ
- [ ] Manual retry: click ğŸ”„ â†’ reprocess
- [ ] Edge cases: very short/long audio, non-Chinese audio
- [ ] LLM failure: verify graceful degradation to raw transcript
- [ ] Concurrent messages: send multiple voices quickly

## Future Enhancements

Not included in initial implementation:
1. Multi-language auto-detection
2. Optional raw transcript output (config toggle)
3. Custom polishing styles (user-configurable prompts)
4. Voice message statistics/analytics
5. Support for additional channels (multi-channel config)

## Monitoring

- Success/failure rate per day
- Whisper API latency percentiles
- Processing time breakdown (download, transcribe, polish, publish)
- Retry attempt distribution
